"""
LangChain Agents åŸºç¡€ä½¿ç”¨ç¤ºä¾‹
å±•ç¤ºå¦‚ä½•åˆ›å»ºagentï¼Œå¦‚ä½•ä½¿ç”¨agentä¸å¤§æ¨¡å‹è¿›è¡Œäº¤äº’
"""

import os

from dotenv import load_dotenv
from langchain.agents import create_agent
from langchain.chat_models import init_chat_model
from langchain.tools import tool
from langchain_core.messages import HumanMessage

# åŠ è½½ç¯å¢ƒå˜é‡
config_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'config.env')
load_dotenv(config_path)

# åˆå§‹åŒ–ç¯å¢ƒå˜é‡
os.environ["OPENAI_API_KEY"] = os.getenv('API_KEY')
os.environ["OPENAI_BASE_URL"] = os.getenv('BASE_URL')
model_name = os.getenv('MODEL')


def init_model(model=model_name):
    """åˆå§‹åŒ– LLM Model"""
    return init_chat_model(
        model=model,
        model_provider="openai",
        temperature=0.7,
        timeout=30,
        max_tokens=1000,
        max_retries=3,
    )


# å®šä¹‰ä¸€äº›åŸºç¡€å·¥å…·
@tool
def calculator(num1: float, operation: str, num2: float) -> float:
    """
    æ‰§è¡ŒåŸºæœ¬æ•°å­¦è¿ç®—çš„è®¡ç®—å™¨å·¥å…·

    Args:
        num1: ç¬¬ä¸€ä¸ªæ•°å­—
        operation: è¿ç®—ç¬¦ (+, -, *, /)
        num2: ç¬¬äºŒä¸ªæ•°å­—

    Returns:
        float: è®¡ç®—ç»“æœ
    """
    print(f"ğŸ§® æ‰§è¡Œè®¡ç®—: {num1} {operation} {num2}")

    if operation == "+":
        return num1 + num2
    elif operation == "-":
        return num1 - num2
    elif operation == "*":
        return num1 * num2
    elif operation == "/":
        if num2 == 0:
            raise ValueError("é™¤æ•°ä¸èƒ½ä¸ºé›¶")
        return num1 / num2
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„è¿ç®—ç¬¦: {operation}")


@tool
def weather_checker(city: str) -> str:
    """
    æŸ¥è¯¢åŸå¸‚å¤©æ°”ä¿¡æ¯çš„å·¥å…·

    Args:
        city: åŸå¸‚åç§°

    Returns:
        str: å¤©æ°”ä¿¡æ¯
    """
    print(f"ğŸŒ¤ï¸ æŸ¥è¯¢ {city} çš„å¤©æ°”")
    # æ¨¡æ‹Ÿå¤©æ°”æ•°æ®
    weather_data = {
        "åŒ—äº¬": "æ™´å¤©ï¼Œæ¸©åº¦ 15Â°C",
        "ä¸Šæµ·": "å¤šäº‘ï¼Œæ¸©åº¦ 18Â°C",
        "å¹¿å·": "é›¨å¤©ï¼Œæ¸©åº¦ 22Â°C",
        "æ·±åœ³": "é˜´å¤©ï¼Œæ¸©åº¦ 20Â°C",
        "æ­å·": "æ™´å¤©ï¼Œæ¸©åº¦ 16Â°C"
    }
    return weather_data.get(city, f"æš‚æ—  {city} çš„å¤©æ°”ä¿¡æ¯")


def basic_agent_demo():
    """åŸºç¡€Agentä½¿ç”¨æ¼”ç¤º"""
    print("ğŸš€ å¼€å§‹ LangChain Agents åŸºç¡€ç¤ºä¾‹æ¼”ç¤º")

    # åˆ›å»ºAgent
    # åˆå§‹åŒ–æ¨¡å‹
    llm = init_model()

    # å®šä¹‰å·¥å…·åˆ—è¡¨
    tools = [calculator]

    # åˆ›å»ºAgentï¼Œä¸»è¦æ˜¯åŸºäºmodelï¼Œ toolsï¼Œç³»ç»Ÿæç¤ºè¯æ¥æ„å»ºagent
    agent = create_agent(
        model=llm,
        tools=tools,
        system_prompt="ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥æ ¹æ®ç”¨æˆ·çš„é—®é¢˜é€‰æ‹©åˆé€‚çš„å·¥å…·æ¥å¸®åŠ©è§£å†³é—®é¢˜ã€‚"
    )

    # æµ‹è¯•ç”¨ä¾‹
    test_queries = [
        "å¸®æˆ‘ä»‹ç»ä¸€ä¸‹æç™½çš„ç”Ÿå¹³",
        "ä»Šå¤©å¤©æ°”ä¸é”™ï¼Œå¸®æˆ‘æ¨èå‡ ä¸ªæœ‰è¶£çš„æ¸¸æˆ",
        "å…ˆè®¡ç®— 100 é™¤ä»¥ 5ï¼Œç„¶åå‘Šè¯‰æˆ‘ä¸Šæµ·çš„å¤©æ°”"
    ]

    print(f"\nğŸ¯ å¼€å§‹æµ‹è¯• {len(test_queries)} ä¸ªé—®é¢˜:")

    for i, query in enumerate(test_queries, 1):
        print(f"\n{'=' * 20} æµ‹è¯• {i}/{len(test_queries)} {'=' * 20}")
        print(f"â“ é—®é¢˜: {query}")

        try:
            # è°ƒç”¨Agentï¼Œä¼ å…¥çš„æ˜¯ä¸€ä¸ªè¾“å…¥å­—å…¸, å…¶ä¸­ messages æ˜¯ä¸€ä¸ªæ¶ˆæ¯åˆ—è¡¨, é™¤äº†ä½¿ç”¨å­—å…¸æ–¹å¼è¡¨ç¤ºæ¶ˆæ¯ä¹‹å¤–ï¼Œè¿˜å¯ä»¥é€šè¿‡ HumanMessage çš„æ–¹å¼ä¼ å…¥
            inputs = {"messages": [{"role": "user", "content": query}]}
            # åŒæ­¥è°ƒç”¨ï¼Œç›´æ¥è·å–è¿”å›ç»“æœ
            response = agent.invoke(inputs)

            # æ˜¾ç¤ºå®Œæ•´å¯¹è¯å†å²ï¼Œå¯¹äºagentï¼Œè°ƒç”¨å·¥å…·æ—¶ï¼Œä¸éœ€è¦åƒmodelä¸€æ ·ï¼Œç”±æˆ‘ä»¬æ¥ç»´æŠ¤å·¥å…·çš„æ‰§è¡Œï¼›å·¥å…·çš„å®Œæ•´æ‰§è¡Œé“¾è·¯éƒ½æ˜¯ç”±Agentæ¥é©±åŠ¨çš„
            print("ğŸ’¬ å¯¹è¯å†å²:")
            for msg in response["messages"]:
                if hasattr(msg, 'content'):
                    print(f"   {msg.type}: {msg.content}")
                elif isinstance(msg, dict):
                    print(f"   {msg.get('role', 'unknown')}: {msg.get('content', '')}")

        except Exception as e:
            print(f"âŒ æ‰§è¡Œå‡ºé”™: {e}")
            continue


def stream_demo():
    """è‡ªå®šä¹‰æç¤ºè¯Agentæ¼”ç¤º"""
    print("\nğŸ¯ Streamè®¿é—®æ¼”ç¤º:")

    llm = init_model()
    tools = [calculator, weather_checker]

    agent = create_agent(llm, tools, system_prompt="""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ™ºèƒ½åŠ©æ‰‹ï¼Œå…·æœ‰ä»¥ä¸‹èƒ½åŠ›ï¼š
            1. æ•°å­¦è®¡ç®— - å¯ä»¥è¿›è¡Œå„ç§æ•°å­¦è¿ç®—
            2. å¤©æ°”æŸ¥è¯¢ - å¯ä»¥æŸ¥è¯¢ä¸­å›½ä¸»è¦åŸå¸‚çš„å¤©æ°”

            è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜é€‰æ‹©æœ€åˆé€‚çš„å·¥å…·æ¥è§£å†³é—®é¢˜ã€‚
            å¦‚æœé—®é¢˜æ¶‰åŠå¤šä¸ªæ­¥éª¤ï¼Œè¯·ä¾æ¬¡æ‰§è¡Œç›¸åº”çš„å·¥å…·è°ƒç”¨ã€‚
            å›ç­”æ—¶è¦æ¸…æ™°ã€å‡†ç¡®ï¼Œå¹¶ç»™å‡ºå®Œæ•´çš„è§£å†³æ–¹æ¡ˆã€‚""")

    queries = [
        "è®¡ç®— 5 * 8",
        "æ¯”è¾ƒä¸€ä¸‹åŒ—äº¬å’Œä¸Šæµ·ä»Šå¤©çš„å¤©æ°”å“ªä¸ªæ›´å¥½"
    ]

    for query in queries:
        print(f"\nâ“ é—®é¢˜: {query}")
        try:
            inputs = {"messages": [HumanMessage(query)]}
            # æ˜¾ç¤ºå®Œæ•´å¯¹è¯å†å²
            print("ğŸ’¬ å¯¹è¯å†å²:")
            # æµå¼è°ƒç”¨ï¼šè¯¥æ¨¡å¼ä¼šåœ¨æ™ºèƒ½ä½“çš„æ¯ä¸ªæ‰§è¡Œæ­¥éª¤å®Œæˆåä¼ è¾“ä¸­é—´æ•°æ®ï¼Œè®©å¼€å‘è€…èƒ½å¤Ÿè§‚å¯Ÿåˆ°å®Œæ•´çš„å†³ç­–è¿‡ç¨‹ï¼Œå¦‚ä¸Šä¾‹æ‰€ç¤ºï¼Œå€¼æµæ¨¡å¼ä¼šåˆ†å››æ¬¡æ›´æ–°æ•°æ®ï¼šHumanMessageï¼ˆç”¨æˆ·è¾“å…¥ï¼‰ã€AIMessageï¼ˆæ¨¡å‹åˆå§‹å“åº”ï¼‰ã€ToolMessageï¼ˆå·¥å…·è°ƒç”¨ç»“æœï¼‰å’Œæœ€ç»ˆçš„AIMessageï¼ˆæ€»ç»“å›ç­”ï¼‰
            last_type = None
            for step in agent.stream(inputs, stream_mode="values"):
                msg = step['messages'][-1]
                if last_type != msg.type:
                    print(f"\n   {msg.type}: ", end='')
                    last_type = msg.type
                print(msg.content, end='', flush=True)

            print("\n\n")
        except Exception as e:
            print(f"âŒ æ‰§è¡Œå‡ºé”™: {e}")


if __name__ == "__main__":
    print("ğŸ¤– LangChain Agents åŸºç¡€ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 50)

    # åŸºç¡€æ¼”ç¤º
    basic_agent_demo()

    # æµå¼æ¼”ç¤º
    stream_demo()

    print("\nâœ… åŸºç¡€Agentsç¤ºä¾‹æ¼”ç¤ºå®Œæˆï¼")
