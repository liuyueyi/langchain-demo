"""
LangChain Agents åŠ¨æ€å·¥å…·è¿›é˜¶ä½¿ç”¨ç¤ºä¾‹
"""

import logging
import os
from dataclasses import dataclass
from typing import Callable

from dotenv import load_dotenv
from langchain.agents import create_agent
from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse, AgentMiddleware
from langchain.chat_models import init_chat_model
from langchain.tools import tool
from langchain_core.messages import HumanMessage
from langgraph.prebuilt.tool_node import ToolCallRequest

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åŠ è½½ç¯å¢ƒå˜é‡
config_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'config-zhipu.env')
load_dotenv(config_path)

# åˆå§‹åŒ–ç¯å¢ƒå˜é‡
os.environ["OPENAI_API_KEY"] = os.getenv('API_KEY')
os.environ["OPENAI_BASE_URL"] = os.getenv('BASE_URL')
model_name = os.getenv('MODEL')


def init_model(model=model_name):
    """åˆå§‹åŒ– LLM Model"""
    return init_chat_model(
        model=model,
        model_provider="openai",
        temperature=0.7,
        timeout=30,
        max_tokens=1500,
        max_retries=3,
    )


# å®šä¹‰ä¸€äº›åŸºç¡€å·¥å…·
@tool
def calculator(num1: float, operation: str, num2: float) -> float:
    """
    æ‰§è¡ŒåŸºæœ¬æ•°å­¦è¿ç®—çš„è®¡ç®—å™¨å·¥å…·

    Args:
        num1: ç¬¬ä¸€ä¸ªæ•°å­—
        operation: è¿ç®—ç¬¦ (+, -, *, /)
        num2: ç¬¬äºŒä¸ªæ•°å­—

    Returns:
        float: è®¡ç®—ç»“æœ
    """
    print(f"ğŸ§® æ‰§è¡Œè®¡ç®—: {num1} {operation} {num2}")

    if operation == "+":
        return num1 + num2
    elif operation == "-":
        return num1 - num2
    elif operation == "*":
        return num1 * num2
    elif operation == "/":
        if num2 == 0:
            raise ValueError("é™¤æ•°ä¸èƒ½ä¸ºé›¶")
        return num1 / num2
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„è¿ç®—ç¬¦: {operation}")


@tool
def weather_checker(city: str) -> str:
    """
    æŸ¥è¯¢åŸå¸‚å¤©æ°”ä¿¡æ¯çš„å·¥å…·

    Args:
        city: åŸå¸‚åç§°

    Returns:
        str: å¤©æ°”ä¿¡æ¯
    """
    print(f"ğŸŒ¤ï¸ æŸ¥è¯¢ {city} çš„å¤©æ°”")
    # æ¨¡æ‹Ÿå¤©æ°”æ•°æ®
    weather_data = {
        "åŒ—äº¬": "æ™´å¤©ï¼Œæ¸©åº¦ 15Â°C",
        "ä¸Šæµ·": "å¤šäº‘ï¼Œæ¸©åº¦ 18Â°C",
        "å¹¿å·": "é›¨å¤©ï¼Œæ¸©åº¦ 22Â°C",
        "æ·±åœ³": "é˜´å¤©ï¼Œæ¸©åº¦ 20Â°C",
        "æ­å·": "æ™´å¤©ï¼Œæ¸©åº¦ 16Â°C"
    }
    return weather_data.get(city, f"æš‚æ—  {city} çš„å¤©æ°”ä¿¡æ¯")


@tool
def web_search(query: str) -> str:
    """
    æ¨¡æ‹Ÿç½‘ç»œæœç´¢å·¥å…·

    Args:
        query: æœç´¢å…³é”®è¯

    Returns:
        str: æœç´¢ç»“æœæ‘˜è¦
    """
    print(f"ğŸ” æœç´¢: {query}")
    # æ¨¡æ‹Ÿæœç´¢ç»“æœ
    search_results = {
        "äººå·¥æ™ºèƒ½å‘å±•": "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè‡´åŠ›äºåˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„æœºå™¨...",
        "Pythonç¼–ç¨‹": "Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œä»¥å…¶ç®€æ´æ˜“è¯»çš„è¯­æ³•å’Œå¼ºå¤§çš„åŠŸèƒ½åº“è€Œé—»å...",
        "æœºå™¨å­¦ä¹ ": "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä½¿è®¡ç®—æœºèƒ½å¤Ÿåœ¨ä¸è¢«æ˜ç¡®ç¼–ç¨‹çš„æƒ…å†µä¸‹ä»æ•°æ®ä¸­å­¦ä¹ ..."
    }
    return search_results.get(query, f"å…³äº'{query}'çš„æœç´¢ç»“æœæ˜¾ç¤ºï¼šè¿™æ˜¯ç›¸å…³çš„çŸ¥è¯†å†…å®¹...")


@dataclass
class UserContext:
    user_role: str


@wrap_model_call
def filter_tools(
        request: ModelRequest,
        handler: Callable[[ModelRequest], ModelResponse],
) -> ModelResponse:
    """Filter tools based on user permissions."""
    # å¦‚æœåœ¨åˆ›å»ºä»£ç†æ—¶å·²çŸ¥æ‰€æœ‰å¯èƒ½çš„å·¥å…·ï¼Œåˆ™å¯ä»¥é¢„å…ˆæ³¨å†Œå®ƒä»¬ï¼Œå¹¶æ ¹æ®çŠ¶æ€ã€æƒé™æˆ–ä¸Šä¸‹æ–‡åŠ¨æ€ç­›é€‰å“ªäº›å·¥å…·å¯ä»¥å…¬å¼€ç»™æ¨¡å‹ã€‚
    user_role = request.runtime.context.user_role

    if user_role == "math":
        # Admins get all tools
        tools = [t for t in request.tools if t.name == "calculator"]
    elif user_role == 'search':
        tools = [t for t in request.tools if t.name == "web_search"]
    elif user_role == 'admin':
        tools = request.tools
    else:
        # Regular users get read-only tools
        tools = []

    return handler(request.override(tools=tools))


def filter_pre_registered_tools():
    # å¦‚æœåœ¨åˆ›å»ºä»£ç†æ—¶å·²çŸ¥æ‰€æœ‰å¯èƒ½çš„å·¥å…·ï¼Œåˆ™å¯ä»¥é¢„å…ˆæ³¨å†Œå®ƒä»¬ï¼Œå¹¶æ ¹æ®çŠ¶æ€ã€æƒé™æˆ–ä¸Šä¸‹æ–‡åŠ¨æ€ç­›é€‰å“ªäº›å·¥å…·å¯ä»¥å…¬å¼€ç»™æ¨¡å‹ã€‚
    print("ğŸš€ å¼€å§‹ LangChain Agents Toolsç¤ºä¾‹æ¼”ç¤º")

    # åˆ›å»ºAgent
    # åˆå§‹åŒ–æ¨¡å‹
    llm = init_model()

    # é¢„å…ˆæ³¨å†Œæ‰€æœ‰çš„å·¥å…·åˆ—è¡¨
    tools = [calculator, weather_checker, web_search]

    # åˆ›å»ºAgentï¼Œä¸»è¦æ˜¯åŸºäºmodelï¼Œ toolsï¼Œç³»ç»Ÿæç¤ºè¯æ¥æ„å»ºagent
    agent = create_agent(
        model=llm,
        tools=tools,
        system_prompt="ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥æ ¹æ®ç”¨æˆ·çš„é—®é¢˜é€‰æ‹©åˆé€‚çš„å·¥å…·æ¥å¸®åŠ©è§£å†³é—®é¢˜ã€‚",
        middleware=[filter_tools]
    )

    # math è§’è‰²çš„ç”¨æˆ·ï¼Œç”¨äºè°ƒç”¨æ•°æ®è®¡ç®—
    response = agent.invoke({"messages": [{"role": "user", "content": "è®¡ç®— 25 ä¹˜ä»¥ 4 ç­‰äºå¤šå°‘ï¼Ÿ"}]},
                            context=UserContext(user_role="math"))
    for msg in response["messages"]:
        print(f"{msg.type}: {msg.content}")

    # search è§’è‰²çš„ç”¨æˆ·ï¼Œç”¨äºè®¿é—®mathçš„å·¥å…·ï¼Œé¢„æœŸæ˜¯æ— æ³•æ­£å¸¸è°ƒç”¨å·¥å…·
    response = agent.invoke({"messages": [{"role": "user", "content": "è®¡ç®— 4 ä¹˜ä»¥ 4 ç­‰äºå¤šå°‘ï¼Ÿ"}]},
                            context=UserContext(user_role="search"))
    for msg in response["messages"]:
        print(f"{msg.type}: {msg.content}")

    # ç»™ä¸€ä¸ªguestè§’è‰²ï¼Œé¢„æœŸæ˜¯æ— æ³•æ­£å¸¸è°ƒç”¨å·¥å…·
    response = agent.invoke({"messages": [{"role": "user", "content": "ä»Šå¤©åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"}]},
                            context=UserContext(user_role="guest"))
    for msg in response["messages"]:
        print(f"{msg.type}: {msg.content}")


class DynamicToolMiddleware(AgentMiddleware):
    """Middleware that registers and handles dynamic tools."""

    def wrap_model_call(self, request: ModelRequest, handler):
        # Add dynamic tool to the request
        # This could be loaded from an MCP server, database, etc.
        updated = request.override(tools=[*request.tools, calculator])
        return handler(updated)

    def wrap_tool_call(self, request: ToolCallRequest, handler):
        # Handle execution of the dynamic tool
        if request.tool_call["name"] == "calculator":
            return handler(request.override(tool=calculator))
        return handler(request)


def runtime_tool_registration():
    """
    å½“åœ¨è¿è¡Œæ—¶å‘ç°æˆ–åˆ›å»ºå·¥å…·æ—¶ï¼ˆä¾‹å¦‚ï¼Œä» MCP æœåŠ¡å™¨åŠ è½½ã€æ ¹æ®ç”¨æˆ·æ•°æ®ç”Ÿæˆæˆ–ä»è¿œç¨‹æ³¨å†Œè¡¨ä¸­è·å–ï¼‰ï¼Œæ‚¨éœ€è¦æ³¨å†Œè¿™äº›å·¥å…·å¹¶åŠ¨æ€å¤„ç†å®ƒä»¬çš„æ‰§è¡Œã€‚
    :return:
    """
    print("ğŸš€ è¿è¡Œæ—¶å·¥å…·æ³¨å†Œç¤ºä¾‹")
    # åˆå§‹åŒ–æ¨¡å‹
    llm = init_model()

    agent = create_agent(
        model=llm,
        tools=[weather_checker],  # Only static tools registered here
        middleware=[DynamicToolMiddleware()],  # åŠ¨æ€å·¥å…·æ³¨å†Œ
    )

    query = "å…ˆè®¡ç®— 100 é™¤ä»¥ 5ï¼Œç„¶åå‘Šè¯‰æˆ‘ä¸Šæµ·çš„å¤©æ°”"
    print(f"\nâ“ é—®é¢˜: {query}")
    try:
        inputs = {"messages": [HumanMessage(query)]}
        # æ˜¾ç¤ºå®Œæ•´å¯¹è¯å†å²
        print("ğŸ’¬ å¯¹è¯å†å²:")
        # æµå¼è°ƒç”¨ï¼šè¯¥æ¨¡å¼ä¼šåœ¨æ™ºèƒ½ä½“çš„æ¯ä¸ªæ‰§è¡Œæ­¥éª¤å®Œæˆåä¼ è¾“ä¸­é—´æ•°æ®ï¼Œè®©å¼€å‘è€…èƒ½å¤Ÿè§‚å¯Ÿåˆ°å®Œæ•´çš„å†³ç­–è¿‡ç¨‹ï¼Œå¦‚ä¸Šä¾‹æ‰€ç¤ºï¼Œå€¼æµæ¨¡å¼ä¼šåˆ†å››æ¬¡æ›´æ–°æ•°æ®ï¼šHumanMessageï¼ˆç”¨æˆ·è¾“å…¥ï¼‰ã€AIMessageï¼ˆæ¨¡å‹åˆå§‹å“åº”ï¼‰ã€ToolMessageï¼ˆå·¥å…·è°ƒç”¨ç»“æœï¼‰å’Œæœ€ç»ˆçš„AIMessageï¼ˆæ€»ç»“å›ç­”ï¼‰
        last_type = None
        for step in agent.stream(inputs, stream_mode="values"):
            msg = step['messages'][-1]
            if last_type != msg.type:
                print(f"\n   {msg.type}: ", end='')
                last_type = msg.type
            print(msg.content, end='', flush=True)

        print("\n\n")
    except Exception as e:
        print(f"âŒ æ‰§è¡Œå‡ºé”™: {e}")


if __name__ == "__main__":
    print("ğŸ”§ LangChain Agents å·¥å…·è¿›é˜¶ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 60)

    # é«˜çº§å·¥å…·æ¼”ç¤º
    filter_pre_registered_tools()

    # é”™è¯¯å¤„ç†æ¼”ç¤º
    runtime_tool_registration()

    print("\nâœ… å·¥å…·è¿›é˜¶ç¤ºä¾‹æ¼”ç¤ºå®Œæˆï¼")
