import os

from dotenv import load_dotenv
from langchain.chat_models import init_chat_model

config_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'config.env')
load_dotenv(config_path)

# åˆå§‹åŒ–ç¯å¢ƒå˜é‡
os.environ["OPENAI_API_KEY"] = os.getenv('API_KEY')
os.environ["OPENAI_BASE_URL"] = os.getenv('BASE_URL')
model = os.getenv('MODEL')


def pretty_print_ai_response(response):
    """
    ç¾åŒ–çš„ AI å“åº”è¾“å‡º
    :param response: å¤§æ¨¡å‹çš„è¿”å›
    :return:
    """
    separator = "=" * 60

    print(f"\n{separator}")
    print("ğŸ¤– AI æ™ºèƒ½å›å¤")
    print(separator)

    # ä¸»è¦å†…å®¹æ˜¾ç¤º
    print(f"\nğŸ’¬ å›å¤å†…å®¹:")
    if hasattr(response, 'content'):
        print(response.content)
    else:
        print(str(response))

        # æŠ€æœ¯ä¿¡æ¯
    print(f"\n{separator}")
    print("ğŸ“Š æŠ€æœ¯è¯¦æƒ…:")
    print(f"  ğŸ“ ç±»å‹: {type(response).__name__}")

    # Token ä½¿ç”¨æƒ…å†µ
    if hasattr(response, 'usage_metadata') and response.usage_metadata:
        print(f"  ğŸ’° Token: {response.usage_metadata}")
    elif hasattr(response, 'usage') and response.usage:
        print(f"  ğŸ’° Token: {response.usage}")
    else:
        print("  ğŸ’° Token: æœªæä¾›")

    # å¯¹è±¡å±æ€§ç»Ÿè®¡
    attr_count = len([attr for attr in dir(response) if not attr.startswith('_')])
    print(f"  ğŸ” å±æ€§æ•°: {attr_count} ä¸ª")
    print(separator)


def simple_invoke(model):
    """
    åŸºç¡€çš„åŸºäºModelçš„å¤§æ¨¡å‹åŒæ­¥è®¿é—®ï¼Œè®¾ç½®è¶…æ—¶æ—¶é—´ã€æ¸©åº¦ã€æœ€å¤§tokené™åˆ¶
    :param model:
    :return:
    """
    # åˆå§‹åŒ– LLM Model
    model = init_chat_model(model=model,
                            model_provider="openai",  # æŒ‡å®šæ¨¡å‹å‚å•†
                            temperature=0.7,  # æ¸©åº¦ï¼Œæ§åˆ¶è¿”å›æ›´ç¨³å®šè¿˜æ˜¯æ›´æœ‰åˆ›é€ åŠ›çš„ç»“æœ
                            timeout=30,  # è®¾ç½®è¶…æ—¶æ—¶é—´ï¼Œå•ä½ç§’
                            max_tokens=1000,  # é™åˆ¶å“åº”ä¸­çš„ä»¤ç‰Œæ€»æ•°ï¼Œä»è€Œæœ‰æ•ˆåœ°æ§åˆ¶è¾“å‡ºçš„é•¿åº¦ã€‚
                            max_retries=3,  # æœ€å¤§å¤±è´¥é‡è¯•æ¬¡æ•°
                            )

    # ç›´æ¥ä½¿ç”¨modelè¿›è¡Œå¤§æ¨¡å‹çš„äº¤äº’
    response = model.invoke("è¯·å†™ä¸€é¦–å…³äºé¢œè‰²çš„äº”è¨€ç»å¥")
    pretty_print_ai_response(response)


print("--" * 30 + " modelç›´æ¥åŒæ­¥è®¿é—® " + "--" * 30)
simple_invoke(model)
